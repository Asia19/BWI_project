{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the train file into smaller ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ad66afa1457e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0msplitfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/train_v2.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m700000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-ad66afa1457e>\u001b[0m in \u001b[0;36msplitfile\u001b[1;34m(infilepath, chunksize)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"../data/train_v2-{i}.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                     \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mwritten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ad66afa1457e>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"../data/train_v2-{i}.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                     \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mwritten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def splitfile(infilepath, chunksize):\n",
    "    i = 1\n",
    "    written = False\n",
    "    with io.open(infilepath, encoding='utf-8') as infile:\n",
    "        while True:\n",
    "            with io.open(f\"../data/train_v2-{i}.txt\", encoding='utf-8', mode='w') as outfile:\n",
    "                for line in (infile.readline() for _ in range(chunksize)):\n",
    "                    outfile.write(line)\n",
    "                written = bool(line)\n",
    "            if not written:\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "splitfile(\"../data/train_v2.txt\", 700000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train corpus\n",
    "### ngrams frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(seq, n, need_sorted=False):\n",
    "    it = iter(seq)\n",
    "    result = list(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        if need_sorted:\n",
    "            result = sorted(result)\n",
    "        yield tuple(result)\n",
    "    for elem in it:\n",
    "        result = result[1:] + [elem,]\n",
    "        if need_sorted:\n",
    "            result = sorted(result)\n",
    "        yield tuple(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shelve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush(local, remote):\n",
    "    for key, value in local.items():\n",
    "        key = repr(key)\n",
    "        remote[key] = remote.get(key, 0) + value\n",
    "\n",
    "    local.clear()\n",
    "    remote.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shelve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-62c37ba91310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/train_v2.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mshelve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unigram_db'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriteback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0munigram_db\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mshelve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bigram_db'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriteback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbigram_db\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mshelve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trigram_db'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriteback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrigram_db\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shelve' is not defined"
     ]
    }
   ],
   "source": [
    "unigram_counter = Counter()\n",
    "bigram_counter = Counter()\n",
    "trigram_counter = Counter()\n",
    "\n",
    "with io.open('../data/train_v2.txt', encoding='utf-8', mode='rt') as file, \\\n",
    "        shelve.open('unigram_db', writeback=True) as unigram_db, \\\n",
    "        shelve.open('bigram_db', writeback=True) as bigram_db, \\\n",
    "        shelve.open('trigram_db', writeback=True) as trigram_db:\n",
    "\n",
    "    for step, line in enumerate(file):\n",
    "\n",
    "        if step % 10000 == 0:\n",
    "            start = time.time()\n",
    "            flush(unigram_counter, unigram_db)\n",
    "            flush(bigram_counter, bigram_db)\n",
    "            flush(trigram_counter, trigram_db)\n",
    "            print(f\"working on {step // 10000}kth line,\\n count of unigram - {len(unigram_counter)}, \\\n",
    "            \\n count of bigram - {len(bigram_counter)},\\n count of trigram - {len(trigram_counter)}\\n \\\n",
    "            time = {start-time.time()}\", end='\\r')\n",
    "\n",
    "        comma_pos = line.find(',')\n",
    "        sentence = line[comma_pos + 1:].replace('\"', ' ').lower()\n",
    "        sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "        unigram_counter.update(sentence)\n",
    "        bigram_counter.update(get_windows(sentence, 2))\n",
    "        trigram_counter.update(get_windows(sentence, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\persi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: save is deprecated. Use insert_one or replace_one instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "d = {'string1' : 1, 'string2' : 2, 'string3' : 3}\n",
    "cl = MongoClient('mongodb://localhost:27017/')\n",
    "db = cl['example_db']\n",
    "example_collection = db['example-collection']\n",
    "for key, value in d.items():\n",
    "    example_collection.save({'key' : key, 'value' : value})\n",
    "    \n",
    "obj = example_collection.find_one({'key':'string4'})\n",
    "print(obj)\n",
    "obj = example_collection.find_one({'key':'string1'})\n",
    "print(obj['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush(local, remote):\n",
    "    for key, value in local.items():\n",
    "        obj = remote.find_one({'key':repr(key)})\n",
    "        r_value = obj['value'] if obj else 0\n",
    "        remote.save({'key' : repr(key), 'value' : r_value + value})\n",
    "        #remote.update_one({'key': repr(key)}, {'$inc': {'value': value}}, upsert=True)\n",
    "    local.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush(local, remote):\n",
    "    print(f'length of voc:{len(local)}')\n",
    "    i = 0\n",
    "    for key, value in local.items():\n",
    "        obj = remote.find_one({'key':repr(key)})\n",
    "        r_value = obj['value'] if obj else 0\n",
    "        remote.save({'key' : repr(key), 'value' : r_value + value})\n",
    "        #remote.update_one({'key': repr(key)}, {'$inc': {'value': value}}, upsert=True)\n",
    "        print(f'i update {i} keys',end='\\r')\n",
    "        i+=1\n",
    "    local.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of voc:0\n",
      "length of voc:0\n",
      "length of voc:0\n",
      "time = 0.0\r",
      "length of voc:5255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\persi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: save is deprecated. Use insert_one or replace_one instead\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of voc:14531\n",
      "length of voc:16339\n",
      "i update 10418 keys\r"
     ]
    }
   ],
   "source": [
    "unigram_counter = Counter()\n",
    "bigram_counter = Counter()\n",
    "trigram_counter = Counter()\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['ngram_db']\n",
    "unigram_db = db['unigram-db']\n",
    "bigram_db = db['bigram-db']\n",
    "trigram_db = db['trigram-db']\n",
    "\n",
    "with io.open('../data/train_v2.txt', encoding='utf-8', mode='rt') as file:\n",
    "\n",
    "    for step, line in enumerate(file):\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            start = time.time()\n",
    "            flush(unigram_counter, unigram_db)\n",
    "            flush(bigram_counter, bigram_db)\n",
    "            flush(trigram_counter, trigram_db)\n",
    "#             print(f\"working on {step // 1000}kth line,\\n count of unigram - {len(unigram_counter)}, \\\n",
    "#             \\n count of bigram - {len(bigram_counter)},\\n count of trigram - {len(trigram_counter)}\\n \\\n",
    "#             time = {start-time.time()}\", end='\\r')\n",
    "            print(f'time = {start-time.time()}', end='\\r')\n",
    "        comma_pos = line.find(',')\n",
    "        sentence = line[comma_pos + 1:].replace('\"', ' ').lower()\n",
    "        sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "        unigram_counter.update(sentence)\n",
    "        bigram_counter.update(get_windows(sentence, 2))\n",
    "        trigram_counter.update(get_windows(sentence, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('../data/train_v2.txt', encoding='utf-8', mode='rt') as file:\n",
    "    step = 0\n",
    "    for line in file:\n",
    "        if not (step % 1000):\n",
    "            print(f\"working on {step // 1000}kth line,\\n count of unigram - {len(unigram_counter)}, \\\n",
    "            \\n count of bigram - {len(bigram_counter)},\\n count of trigram - {len(trigram_counter)}\", end='\\r')\n",
    "        comma_pos = line.find(',')\n",
    "        sentence = re.sub('\"', '', line[comma_pos+1:]).lower()\n",
    "        sentence = nltk.word_tokenize(sentence)\n",
    "        \n",
    "#         for token in sentence:\n",
    "#             unigram_counter[repr(token)] += 1\n",
    "#         for bigram in list(get_windows(sentence, 2)):\n",
    "#             bigram_counter[repr(bigram)] += 1    \n",
    "#         for trigram in list(get_windows(sentence, 3)):\n",
    "#             trigram_counter[repr(trigram)] += 1  \n",
    "#         for unigram in sentence:\n",
    "#             if not (unigram in unigram_counter):\n",
    "#                 unigram_counter[unigram] = 0\n",
    "#             unigram_counter[unigram] += 1\n",
    "# #         print(unigram_seq)\n",
    "# #         unigram_counter.update(sentence)\n",
    "#         bigram_seq = [repr(bigram) for bigram in get_windows(sentence, 2)]\n",
    "#         for bigram in bigram_seq:\n",
    "#             if not (bigram in bigram_counter):\n",
    "#                 bigram_counter[bigram] = 0\n",
    "#             bigram_counter[bigram] += 1\n",
    "#         print('f')\n",
    "#         trigram_seq = [repr(trigram) for trigram in get_windows(sentence, 3)]\n",
    "#         for trigram in trigram_seq:\n",
    "#             if not (trigram in trigram_counter):\n",
    "#                 trigram_counter[trigram] = 0\n",
    "#             trigram_counter[trigram] += 1\n",
    "#         trigram_counter.update(trigram_seq)\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of all unigram in train corpus: {len(unigram_counter)}')\n",
    "unigram_counter.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of all bigram in train corpus: {len(bigram_counter)}')\n",
    "bigram_counter.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of all trigram in train corpus: {len(trigram_counter)}')\n",
    "trigram_counter.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
