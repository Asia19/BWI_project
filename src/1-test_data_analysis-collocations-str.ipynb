{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/unigram_counter_test_str.pickle', 'rb') as unigram_file, \\\n",
    "        open('../data/bigram_counter_test_str.pickle', 'rb') as bigram_file, \\\n",
    "        open('../data/trigram_counter_test_str.pickle', 'rb') as trigram_file,\\\n",
    "        open('../data/tagged_unigrams_counter_test_str.pickle', 'rb') as tagged_unigram_file, \\\n",
    "        open('../data/tagged_bigrams_counter_test_str.pickle', 'rb') as tagged_bigram_file, \\\n",
    "        open('../data/tagged_trigrams_counter_test_str.pickle', 'rb') as tagged_trigram_file:\n",
    "    unigram_counter = pickle.load(unigram_file)\n",
    "    bigram_counter = pickle.load(bigram_file)\n",
    "    trigram_counter = pickle.load(trigram_file)    \n",
    "    tagged_unigram_counter = pickle.load(tagged_unigram_file)\n",
    "    tagged_bigram_counter = pickle.load(tagged_bigram_file)\n",
    "    tagged_trigram_counter = pickle.load(tagged_trigram_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = []\n",
    "with open('../data/test_v2-preprocessed.txt','rt') as file:\n",
    "    for line in file:\n",
    "        test_corpus.append(line.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLLOCATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JJ - adjective or numeral, JJR  - adjective, JJS - adjective, superlative\n",
    "adjs = ['JJ','JJR','JJS']\n",
    "# NN noun, common; NNP - noun, proper, sing.; NNPS - noun, proper, plural; NNS - noun, common, plural\n",
    "nouns = ['NN','NNS','NNP','NNPS']\n",
    "tag_combs = []\n",
    "for noun in nouns:\n",
    "    tag_combs += [(adj, noun) for adj in adjs] # A,N\n",
    "    for adj in adjs:\n",
    "        for noun_ in nouns:\n",
    "            tag_combs.append((adj, noun, noun_)) # A, N, N\n",
    "            tag_combs.append((noun, adj, noun_)) # N, A, N\n",
    "        tag_combs += [(adj, adj_, noun) for adj_ in adjs] # A, A, N\n",
    "    for noun_ in nouns:\n",
    "        tag_combs += [(noun, noun_, noun__) for noun__ in nouns] # N, N, N\n",
    "        tag_combs += [(noun, 'IN', noun_)] # N, P, N\n",
    "    tag_combs += [(noun_, noun) for noun_ in nouns] # N, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common(test_func, tagged_ngram_counter, reverse=True, m=slice(0,20)):\n",
    "    most_common = sorted(test_func, key=test_func.get, reverse=reverse)[m]\n",
    "    print(\"               ngram              |  count  |   test   \")\n",
    "    for tagged_ngram in most_common:\n",
    "        ngram, _ = tagged_ngram\n",
    "        print(f\"{repr(ngram):^34}|{repr(tagged_ngram_counter[tagged_ngram]):^9}|{test_func[tagged_ngram]:^8.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 20px\">\n",
    "$$t = \\frac{\\bar{X} - \\mu}{\\sqrt{\\frac{s^2}{N}}}$$\n",
    "<br><div style=\"font-size:15px\">\n",
    "$\\mu=p(w1,w2)=p(w1)*p(w2)=\\frac{count(w1)}{n_{bigrams}}\\frac{count(w2)}{n_{bigrams}}$\n",
    "<br>$\\bar{X}=p(w1,w2)=\\frac{count(w1,w2)}{n_{bigrams}}$\n",
    "<br>$s^2=p(w1,w2)*\\left(1-p(w1,w2)\\right)\\approx p(w1,w2),$\n",
    "<br>because probability of each bigram is very small $\\Rightarrow (1-p) \\approx 1$\n",
    "    \n",
    "    \n",
    "$$t = \\frac{\\frac{count(w1,w2)}{n_{bigrams}} - \\frac{count(w1)*count(w2)}{n_{bigrams}^2}}{\\sqrt{\\frac{count(w1,w2)}{n_{bigrams}^2}}} = \\sqrt{count(w1,w2)} - \\frac{count(w1)*count(w2)}{n*\\sqrt{count(w1,w2)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bigram_counter = Counter()\n",
    "for tagged_bigram, count in tagged_bigram_counter.items():\n",
    "    _, tags = tagged_bigram\n",
    "    if tags in tag_combs:\n",
    "        filtered_bigram_counter[tagged_bigram] = count\n",
    "        \n",
    "student_t2 = dict()\n",
    "n_bigrams = sum(bigram_counter.values())\n",
    "for tagged_bigram, count in filtered_bigram_counter.items():\n",
    "    bigram, _ = tagged_bigram\n",
    "    w1, w2 = bigram.split()\n",
    "    student_t2[tagged_bigram] = math.sqrt(count) \n",
    "    student_t2[tagged_bigram] -= unigram_counter[w1] * unigram_counter[w2] / n_bigrams / math.sqrt(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ngram              |  count  |   test   \n",
      "            'new york'            |  3290   |  57.2  \n",
      "             \"don 't\"             |    9    |  51.2  \n",
      "             \"don 't\"             |   27    |  51.2  \n",
      "         'united states'          |  2429   |  49.4  \n",
      "           'last year'            |  2540   |  49.3  \n",
      "            'per cent'            |   22    |  47.8  \n",
      "           'last week'            |  1610   |  39.5  \n",
      "            \"didn 't\"             |   22    |  37.2  \n",
      "         'prime minister'         |  1322   |  36.4  \n",
      "            'i think'             |    7    |  34.1  \n",
      "          'los angeles'           |   486   |  33.2  \n",
      "          'los angeles'           |   362   |  33.2  \n",
      "           'last month'           |  1054   |  32.1  \n",
      "            \"doesn 't\"            |   15    |  32.0  \n",
      "          'white house'           |  1029   |  31.9  \n",
      "          'barack obama'          |   801   |  30.2  \n",
      "          'barack obama'          |   25    |  30.2  \n",
      "        'chief executive'         |   777   |  29.9  \n",
      "        'chief executive'         |   74    |  29.9  \n",
      "           'first time'           |   958   |  29.6  \n",
      "              '/ /'               |   16    |  28.2  \n",
      "              '/ /'               |   306   |  28.2  \n",
      "              '/ /'               |   31    |  28.2  \n",
      "              '/ /'               |   10    |  28.2  \n",
      "          'health care'           |   774   |  27.7  \n",
      "            'пїѕ пїѕ'             |   36    |  27.5  \n",
      "            'пїѕ пїѕ'             |   70    |  27.5  \n",
      "            'пїѕ пїѕ'             |    9    |  27.5  \n",
      "            'пїѕ пїѕ'             |   13    |  27.5  \n",
      "            'пїѕ пїѕ'             |    6    |  27.5  \n",
      "             \"isn 't\"             |    6    |  26.5  \n",
      "             \"isn 't\"             |    2    |  26.5  \n",
      "             \"isn 't\"             |   15    |  26.5  \n",
      "             \"isn 't\"             |    8    |  26.5  \n",
      "             'i don'              |   26    |  26.4  \n",
      "           'next year'            |   619   |  25.5  \n",
      "             \"won 't\"             |    1    |  25.2  \n",
      "          '/ prnewswire'          |   206   |  24.8  \n",
      "          'prnewswire /'          |   49    |  24.8  \n",
      "          'prnewswire /'          |   260   |  24.8  \n",
      "          '/ prnewswire'          |   49    |  24.8  \n",
      "          '/ prnewswire'          |   51    |  24.8  \n",
      "          'wall street'           |   136   |  24.2  \n",
      "          'wall street'           |   401   |  24.2  \n",
      "        'associated press'        |   526   |  23.4  \n",
      "            'web site'            |   380   |  23.3  \n",
      "            'web site'            |   127   |  23.3  \n",
      "          'human rights'          |   500   |  22.5  \n",
      "     'prnewswire-firstcall /'     |   224   |  22.3  \n",
      "     'prnewswire-firstcall /'     |   20    |  22.3  \n",
      "         'climate change'         |   409   |  21.8  \n",
      "         'vice president'         |   464   |  21.5  \n",
      "          'north korea'           |   298   |  21.3  \n",
      "          'north korea'           |   100   |  21.3  \n",
      "           \"couldn 't\"            |    6    |  20.6  \n",
      "        'president obama'         |   13    |  20.3  \n",
      "        'president obama'         |   342   |  20.3  \n",
      "          'south africa'          |   95    |  20.3  \n",
      "          'south africa'          |   199   |  20.3  \n",
      "         'san francisco'          |   320   |  20.1  \n",
      "         'supreme court'          |   368   |  19.9  \n",
      "         'supreme court'          |   27    |  19.9  \n",
      "        'president barack'        |   376   |  19.8  \n",
      "           'world cup'            |   388   |  19.7  \n",
      "          'high school'           |   384   |  19.4  \n",
      "         'third quarter'          |   369   |  19.1  \n",
      "          'gordon brown'          |   108   |  18.9  \n",
      "          'gordon brown'          |   72    |  18.9  \n",
      "         'united nations'         |   357   |  18.8  \n",
      "           'next week'            |   330   |  18.8  \n",
      "          'real estate'           |   352   |  18.7  \n",
      "           'same time'            |   370   |  18.6  \n",
      "          'john mccain'           |   309   |  18.5  \n",
      "          'john mccain'           |   20    |  18.5  \n",
      "         'premier league'         |   79    |  18.2  \n",
      "         'premier league'         |   184   |  18.2  \n",
      "         'first quarter'          |   349   |  18.1  \n",
      "          'news agency'           |   334   |  18.1  \n",
      "          'south korea'           |   218   |  18.0  \n",
      "           'hong kong'            |   154   |  17.9  \n",
      "           'hong kong'            |   106   |  17.9  \n",
      "        'federal reserve'         |   323   |  17.9  \n",
      "         'fourth quarter'         |   323   |  17.9  \n",
      "            \"hasn 't\"             |    4    |  17.7  \n",
      "            \"hasn 't\"             |    9    |  17.7  \n",
      "         'second quarter'         |   319   |  17.6  \n",
      "          'middle east'           |   229   |  17.6  \n",
      "          'middle east'           |    7    |  17.6  \n",
      "    '/ prnewswire-usnewswire'     |   148   |  17.6  \n",
      "    'prnewswire-usnewswire /'     |   29    |  17.6  \n",
      "    'prnewswire-usnewswire /'     |   118   |  17.6  \n",
      "        'financial crisis'        |   312   |  17.5  \n",
      "         'european union'         |   302   |  17.5  \n",
      "           'last night'           |   325   |  17.3  \n",
      "           'first half'           |   313   |  17.2  \n",
      "          'recent years'          |   314   |  17.1  \n",
      "         'interest rates'         |   294   |  17.1  \n",
      "      'obama administration'      |   44    |  16.9  \n",
      "      'obama administration'      |   246   |  16.9  \n",
      "           'york city'            |   277   |  16.8  \n"
     ]
    }
   ],
   "source": [
    "get_most_common(student_t2, tagged_bigram_counter, reverse=True, m=slice(0,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trigram_counter = Counter()\n",
    "for tagged_trigram, count in tagged_trigram_counter.items():\n",
    "    _, tags = tagged_trigram\n",
    "    if tags in tag_combs:\n",
    "        filtered_trigram_counter[tagged_trigram] = count\n",
    "        \n",
    "student_t3 = dict()\n",
    "n_trigrams = sum(trigram_counter.values())\n",
    "for tagged_trigram, count in filtered_trigram_counter.items():\n",
    "    trigram, _ = tagged_trigram\n",
    "    w1, w2, w3 = trigram.split()\n",
    "    student_t3[tagged_trigram] = math.sqrt(count) \n",
    "    student_t3[tagged_trigram] -= unigram_counter[w1] * unigram_counter[w2] * \\\n",
    "        unigram_counter[w3] / (n_trigrams * math.sqrt(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ngram              |  count  |   test   \n",
      "     'hillary rodham clinton'     |   129   |  9.7   \n",
      "     'gross domestic product'     |   85    |  7.3   \n",
      "             '= = ='              |   52    |  7.2   \n",
      "    'greenhouse gas emissions'    |   70    |  6.4   \n",
      "    'chancellor angela merkel'    |   41    |  6.3   \n",
      "      'speaker nancy pelosi'      |   39    |  6.1   \n",
      "        'osama bin laden'         |   37    |  6.0   \n",
      "             '* * *'              |   45    |  5.7   \n",
      "         'annum + bonus'          |   32    |  5.3   \n",
      "     'nasdaq composite index'     |   31    |  5.2   \n",
      "         'rio de janeiro'         |   28    |  5.1   \n",
      "     'chairman ben bernanke'      |   47    |  5.1   \n",
      "       'nobel peace prize'        |   38    |  5.1   \n",
      "           'вђљ г‚ в®'            |   24    |  4.9   \n",
      "      'minister ehud olmert'      |   28    |  4.9   \n",
      "    'german chancellor angela'    |   30    |  4.9   \n",
      "          'san suu kyi'           |   27    |  4.8   \n",
      " 'secretary-general ban ki-moon'  |   22    |  4.6   \n",
      "     'state condoleezza rice'     |   51    |  4.5   \n",
      "         'lula da silva'          |   20    |  4.5   \n",
      "   'umar farouk abdulmutallab'    |   19    |  4.4   \n",
      "       'pope benedict xvi'        |   19    |  4.3   \n",
      "          'aung san suu'          |   20    |  4.2   \n",
      "      'president hu jintao'       |   26    |  4.1   \n",
      "    'carbon dioxide emissions'    |   23    |  4.1   \n",
      "'relevant tangential information' |   18    |  4.0   \n",
      "       'pope benedict xvi'        |   16    |  3.9   \n",
      "        'hang seng index'         |   16    |  3.9   \n",
      "   'benchmark 10-year treasury'   |   19    |  3.8   \n",
      "      'embryonic stem cells'      |   15    |  3.8   \n",
      "      'united arab emirates'      |   43    |  3.7   \n",
      "  'improvised explosive devices'  |   14    |  3.7   \n",
      "     'minister nawaz sharif'      |   16    |  3.7   \n",
      "       'leader harry reid'        |   35    |  3.7   \n",
      "      'st. louis cardinals'       |   17    |  3.7   \n",
      "        'san diego padres'        |   16    |  3.6   \n",
      "     'roman catholic church'      |   26    |  3.6   \n",
      "    'rep. gabrielle giffords'     |   13    |  3.6   \n",
      "          'kim jong il'           |   13    |  3.6   \n",
      "   'president dmitry medvedev'    |   25    |  3.6   \n"
     ]
    }
   ],
   "source": [
    "get_most_common(student_t3, tagged_trigram_counter, m=slice(0,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\chi^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 306kth line\r"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_ngrams(sentence, n):\n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        bigram = sentence[i:i+n]\n",
    "        yield bigram\n",
    "        yield bigram[::-1]\n",
    "        \n",
    "bigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for step, line in enumerate(test_corpus):\n",
    "    for w1, w2 in get_ngrams(line, 2):\n",
    "        bigram_model[w1][w2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sq = dict()\n",
    "for tagged_bigram, _ in filtered_bigram_counter.items():\n",
    "    bigram, _ = tagged_bigram\n",
    "    w1, w2 = bigram.split()\n",
    "    o11 = bigram_model[w1][w2]\n",
    "    o12 = sum(bigram_model[w2].values()) - o11\n",
    "    o21 = sum(bigram_model[w1].values()) - o11\n",
    "    o22 = n_bigrams - o11 - o12 - o21\n",
    "    chi_sq[tagged_bigram] = n_bigrams * (o11 * o22 - o12 * o21)**2\n",
    "    chi_sq[tagged_bigram] /= ((o11 + o12)*(o11 + o21)*(o12 + o22)*(o21 + o22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ngram              |  count  |   test   \n",
      "        'more immigrants'         |    1    |  0.0   \n",
      "          'health firms'          |    1    |  0.0   \n",
      "         'hospital today'         |    2    |  0.0   \n",
      "           'long movie'           |    1    |  0.0   \n",
      "          'family movie'          |    1    |  0.0   \n",
      "         'strategy game'          |    1    |  0.0   \n",
      "       'organization money'       |    1    |  0.0   \n",
      "          'york streets'          |    1    |  0.0   \n",
      "          'economy cars'          |    1    |  0.0   \n",
      "         'review system'          |    1    |  0.0   \n",
      "           'ap reports'           |    1    |  0.0   \n",
      "        'cost management'         |    1    |  0.0   \n",
      "         'weapons school'         |    1    |  0.0   \n",
      "          'average per'           |    1    |  0.0   \n",
      "       'american standards'       |    1    |  0.0   \n",
      "          'way airlines'          |    1    |  0.0   \n",
      "           'same hour'            |    1    |  0.0   \n",
      "          'job officer'           |    1    |  0.0   \n",
      "           'eu support'           |    1    |  0.0   \n",
      "           'sea south'            |    1    |  0.0   \n"
     ]
    }
   ],
   "source": [
    "get_most_common(chi_sq, tagged_bigram_counter, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ngram              |  count  |   test   \n",
      "         '-great -great'          |    1    |5239824.4\n",
      "         '-great -great'          |    1    |5239824.4\n",
      "         '-great -great'          |    3    |5239824.4\n",
      "     'tapeshwar vishwakarma'      |    1    |3772675.5\n",
      "           'zuo lianbi'           |    1    |3772675.5\n",
      "         'soud baкјalawy'         |    1    |3772675.5\n",
      "         'jaysuma saidy'          |    1    |3772675.5\n",
      "   'noluthando mayende-sibiya'    |    1    |3772675.5\n",
      "           'rxc7 bxc7'            |    1    |3772675.5\n",
      "           'kola liadi'           |    1    |3772675.5\n",
      "           'igam ogam'            |    1    |3772675.5\n",
      "      'diarmaid macculloch'       |    1    |3772675.5\n",
      "         'maka chawoneka'         |    1    |3772675.5\n",
      "          'sajjan gohel'          |    1    |3772675.5\n",
      "          'senny manave'          |    1    |3772675.5\n",
      "        'krysztof wiecek'         |    1    |3772675.5\n",
      "       'ladenburg thalmann'       |    1    |3772675.5\n",
      "       'liette tousignant'        |    1    |3772675.5\n",
      "      'nazamuddin mohammidy'      |    1    |3772675.5\n",
      "         'temir sariyev'          |    1    |3772675.5\n"
     ]
    }
   ],
   "source": [
    "get_most_common(chi_sq, tagged_bigram_counter, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# likelyhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_likelyhood2 = dict()\n",
    "for tagged_bigram, c12 in filtered_bigram_counter.items():\n",
    "    bigram, _ = tagged_bigram\n",
    "    w1, w2 = bigram.split()\n",
    "    c1, c2 = unigram_counter[w1], unigram_counter[w2] \n",
    "#     c1, c2, c12 = sum(bigram_model[w1].values()), sum(bigram_model[w2].values()), bigram_model[w1][w2]\n",
    "    max_likelyhood2[tagged_bigram] = np.log(c12 * n_bigrams / c1 / c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ngram              |  count  |   test   \n",
      "         'safwat hijazi'          |    1    |  15.8  \n",
      "        'sadafumi kawato'         |    1    |  15.8  \n",
      "       'simгіn bolг\\xadvar'       |    1    |  15.8  \n",
      "      'super-chic workboot'       |    1    |  15.8  \n",
      "        'rajne soderberg'         |    1    |  15.8  \n",
      "     'tapeshwar vishwakarma'      |    1    |  15.8  \n",
      "           'zuo lianbi'           |    1    |  15.8  \n",
      "        'taichiro kiyota'         |    1    |  15.8  \n",
      "   'receptor-associated kinase'   |    1    |  15.8  \n",
      "    'french-trained gendarme'     |    1    |  15.8  \n",
      "        'prгєt-г -porter'         |    1    |  15.8  \n",
      "          'antti niemi'           |    1    |  15.8  \n",
      "         'soud baкјalawy'         |    1    |  15.8  \n",
      "         'brimin kipruto'         |    1    |  15.8  \n",
      " \"'brien-trained four-year-olds\"  |    1    |  15.8  \n",
      "         'emneth hungate'         |    1    |  15.8  \n",
      "         'amancio ortego'         |    1    |  15.8  \n",
      "          'ioana raluca'          |    1    |  15.8  \n",
      "      'tineola bisselliella'      |    1    |  15.8  \n",
      "          'jarle nilsen'          |    1    |  15.8  \n"
     ]
    }
   ],
   "source": [
    "get_most_common(max_likelyhood2, tagged_bigram_counter, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_likelyhood3 = dict()\n",
    "for tagged_trigram, c123 in filtered_trigram_counter.items():\n",
    "    trigram, _ = tagged_trigram\n",
    "    s23 = trigram.rfind(' ')\n",
    "    w12, w3 = trigram[:s23], trigram[s23+1:]\n",
    "    c12, c3 = bigram_counter[w12] , unigram_counter[w3] \n",
    "    max_likelyhood3[tagged_trigram] = np.log(c123 * n_bigrams / c12 / c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ngram              |  count  |   test   \n",
      "  'passage between livestockism'  |    1    |  15.8  \n",
      "         'qadri al ahdal'         |    1    |  15.8  \n",
      "        'samir al quntar'         |    1    |  15.8  \n",
      "       'pit near chessell'        |    1    |  15.8  \n",
      "       'lars ole orjaseter'       |    1    |  15.8  \n",
      "        'salon du dessin'         |    1    |  15.8  \n",
      "    'technology website heise'    |    1    |  15.8  \n",
      "         'roche / chugai'         |    1    |  15.8  \n",
      "  'euromeetings president rajne'  |    1    |  15.8  \n",
      "   'president rajne soderberg'    |    1    |  15.8  \n",
      "    'general anthony krastek'     |    1    |  15.8  \n",
      "    'professor donald macrae'     |    1    |  15.8  \n",
      "       'alila villas soori'       |    1    |  15.8  \n",
      "'interleukin-1 receptor-associated kinase'|    1    |  15.8  \n",
      "       'design new get-ups'       |    1    |  15.8  \n",
      " 'former french-trained gendarme' |    1    |  15.8  \n",
      "     'paris prгєt-г -porter'      |    1    |  15.8  \n",
      "      'general tom perrelli'      |    1    |  15.8  \n",
      "       'fulham antti niemi'       |    1    |  15.8  \n",
      "    'champion brimin kipruto'     |    1    |  15.8  \n"
     ]
    }
   ],
   "source": [
    "get_most_common(max_likelyhood3, tagged_trigram_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "\n",
    "words = list(chain.from_iterable(test_corpus))\n",
    "bigram_finder = BigramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', \"''\\n\"),\n",
       " ('``', \"''\"),\n",
       " ('of', 'the'),\n",
       " ('in', 'the'),\n",
       " (\"''\\n\", 'the'),\n",
       " (',', '``'),\n",
       " ('on', 'the'),\n",
       " (\"''\\n\", 'but'),\n",
       " (',', 'which'),\n",
       " (',', 'but'),\n",
       " ('said', '.'),\n",
       " ('to', 'be'),\n",
       " (',', 'and'),\n",
       " ('at', 'the'),\n",
       " ('for', 'the'),\n",
       " (\"''\\n\", 'it'),\n",
       " (\"''\\n\", 'he'),\n",
       " (\"''\\n\", 'i'),\n",
       " (',', 'who'),\n",
       " ('?', \"''\\n\"),\n",
       " ('more', 'than'),\n",
       " ('has', 'been'),\n",
       " ('will', 'be'),\n",
       " ('in', 'a'),\n",
       " ('have', 'been'),\n",
       " ('from', 'the'),\n",
       " ('he', 'said'),\n",
       " ('it', 'was'),\n",
       " ('it', 'is'),\n",
       " ('it', \"'s\"),\n",
       " ('as', 'a'),\n",
       " ('the', 'first'),\n",
       " ('by', 'the'),\n",
       " ('with', 'the'),\n",
       " ('one', 'of'),\n",
       " ('he', 'was'),\n",
       " ('with', 'a'),\n",
       " ('to', 'the'),\n",
       " ('new', 'york'),\n",
       " (\"''\\n\", 'we'),\n",
       " ('according', 'to'),\n",
       " (')', '-'),\n",
       " ('the', 'world'),\n",
       " (\"''\", 'he'),\n",
       " (\"''\", 'said'),\n",
       " ('would', 'be'),\n",
       " ('had', 'been'),\n",
       " ('for', 'a'),\n",
       " ('is', 'a'),\n",
       " ('don', \"'t\"),\n",
       " (\"''\\n\", 'this'),\n",
       " (',', 'including'),\n",
       " ('last', 'year'),\n",
       " (\"''\\n\", 'they'),\n",
       " ('the', 'company'),\n",
       " ('the', 'same'),\n",
       " ('united', 'states'),\n",
       " ('over', 'the'),\n",
       " ('the', 'united'),\n",
       " ('(', 'ap'),\n",
       " ('ap', ')'),\n",
       " ('out', 'of'),\n",
       " ('per', 'cent'),\n",
       " (\"''\\n\", 'there'),\n",
       " ('this', 'year'),\n",
       " ('such', 'as'),\n",
       " ('part', 'of'),\n",
       " ('at', 'least'),\n",
       " (')', '--'),\n",
       " (\"''\\n\", 'if'),\n",
       " ('that', 'the'),\n",
       " (',', 'said'),\n",
       " ('the', 'government'),\n",
       " ('the', 'country'),\n",
       " ('to', 'make'),\n",
       " (':', '``'),\n",
       " ('they', 'are'),\n",
       " ('of', 'a'),\n",
       " (',', 'according'),\n",
       " (')', ','),\n",
       " ('did', 'not'),\n",
       " ('however', ','),\n",
       " ('there', 'is'),\n",
       " ('into', 'the'),\n",
       " ('a', 'new'),\n",
       " ('that', 'he'),\n",
       " ('the', 'u.s.'),\n",
       " ('to', 'get'),\n",
       " ('as', 'well'),\n",
       " (\"''\\n\", 'she'),\n",
       " ('said', 'he'),\n",
       " ('number', 'of'),\n",
       " ('is', 'not'),\n",
       " ('the', 'new'),\n",
       " ('year', '.'),\n",
       " (',', 'he'),\n",
       " ('they', 'were'),\n",
       " ('the', 'most'),\n",
       " (\"''\", \"''\\n\"),\n",
       " ('and', 'other')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_finder.nbest(BigramAssocMeasures.student_t, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
